# ===========================================
# MCP CHATBOT PLATFORM CONFIGURATION
# ===========================================
# Performance optimizations applied:
# â€¢ Connection pooling: 10/5 (max/keepalive)
# â€¢ Request timeout: 30s (reduced from 60s)
# â€¢ MCP connection rate limiting: 5 concurrent
# â€¢ Database: WAL mode + optimized indexing
# â€¢ Configuration caching + event-driven updates

# 1. CHAT PLATFORM SETTINGS
# ===========================================
chat:
  # Real-time Communication
  websocket:
    # Server endpoints
    host: "localhost"
    port: 8000
    endpoint: "/ws/chat"

    # Security & CORS
    allow_origins: ["*"]
    allow_credentials: true

    # Connection settings
    max_message_size: 16777216  # 16MB
    ping_interval: 20
    ping_timeout: 10

  # Core Chat Behavior
  service:
    # AI Personality
    system_prompt: |
      You are a helpful assistant with a sense of humor.
      You have access to to a list of tools like setting your own configuration.

    # Response streaming
    streaming:
      enabled: true
      persistence:
        persist_deltas: false      # Performance mode
        interval_ms: 200           # Flush every 200ms
        min_chars: 1024            # Or when buffer reaches 1024 chars

    # Tool execution limits
    max_tool_hops: 8

    # User experience
    tool_notifications:
      enabled: true
      show_args: true
      icon: "ðŸ”§"
      format: "{icon} Executing tool: {tool_name}"

    # Service logging
    logging:
      tool_execution: true
      tool_results: true
      result_truncate_length: 200
      system_prompt: false
      llm_replies: false
      llm_reply_truncate_length: 500

# 2. DATA STORAGE & PERSISTENCE
# ===========================================
chat:
  storage:
    # Database configuration
    persistence:
      db_path: "chat_history.db"

      # Data retention policies
      retention:
        max_age_hours: 24        # Messages older than 24h
        max_messages: 1000       # Total messages across all sessions
        max_sessions: 2          # Active conversation sessions
        cleanup_interval_minutes: 30  # How often (minutes) to check for max_age_hours

        # Clear triggers and history management
        clear_triggers_before_full_wipe: 2  # Clear history after N clear triggers
        # auto_cleanup_on_restart removed - history preserved across restarts

      # Session management
      saved_sessions:
        enabled: false
        retention_days: null     # Indefinite
        max_saved: 50

# 3. AI/LLM PROVIDER CONFIGURATION
# ===========================================
llm:
  # Active provider selection
  active: "openrouter"

  # Provider configurations
  providers:
    # OpenAI models
    openai:
      base_url: "https://api.openai.com/v1"
      model: "gpt-4o-mini"
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0

    openai_reasoning:
      base_url: "https://api.openai.com/v1"
      model: "o1-preview"
      max_completion_tokens: 8192

    # Groq models
    groq:
      base_url: "https://api.groq.com/openai/v1"
      model: "llama-3.3-70b-versatile"
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      response_format: {"type": "text"}

    # OpenRouter models (active)
    openrouter:
      base_url: "https://openrouter.ai/api/v1"
      model: "openai/gpt-4o-mini"
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      transforms: ["middle-out"]

    openrouter_reasoning:
      base_url: "https://openrouter.ai/api/v1"
      model: "openai/o3-mini"
      temperature: 0.7
      max_tokens: 8192
      reasoning_effort: "high"
      include_thinking: true

    # Anthropic models (via OpenRouter)
    anthropic_thinking:
      base_url: "https://openrouter.ai/api/v1"
      model: "anthropic/claude-3-opus"
      temperature: 0.7
      max_tokens: 4096
      show_reasoning: true
      thinking_mode: "step_by_step"

    # Template for custom providers
    custom_provider:
      base_url: "https://api.example.com/v1"
      model: "custom-model-v2"
      temperature: 0.8
      max_tokens: 2048

      # Custom parameters (add any provider-specific params)
      custom_param1: "value1"
      custom_param2: 42
      nested_config:
        sub_param: "nested_value"

# 4. NETWORK & CONNECTION SETTINGS
# ===========================================
connection_pool:
  # HTTP client connection management
  max_connections: 10           # Max concurrent connections
  max_keepalive_connections: 5  # Persistent connections
  keepalive_expiry_seconds: 30  # Connection expiry

  # Timeouts & reliability
  request_timeout_seconds: 30   # Initial response timeout
  total_timeout_seconds: 120    # Total request timeout

  # Connection monitoring
  logging:
    enabled: true
    connection_events: true
    pool_stats: true
    pool_stats_interval_seconds: 60
    http_requests: false
    connection_reuse: false
    max_log_entries: 1000

# 5. MONITORING & LOGGING
# ===========================================
logging:
  # Global logging settings
  level: "INFO"
  format: "%(asctime)s - %(levelname)s - %(message)s"

  # Connection-specific logging (can be filtered)
  # filters:
  #   connection_logs:
  #     (): src.clients.llm_client
  #     (): src.clients.mcp_client
  #     connection_events: true

# 6. EXTERNAL INTEGRATIONS
# ===========================================
mcp:
  # Server configuration file
  config_file: "servers_config.json"

  # Connection management
  connection:
    # Retry behavior
    max_reconnect_attempts: 5
    initial_reconnect_delay: 1.0
    max_reconnect_delay: 30.0

    # Timeouts
    connection_timeout: 30.0
    ping_timeout: 10.0

    # MCP-specific logging
    logging:
      enabled: true
      connection_attempts: true
      health_checks: false
      tool_calls: false

# ===========================================
# CONFIGURATION END
# ===========================================
